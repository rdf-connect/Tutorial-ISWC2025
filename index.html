<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta charset="utf-8" />
  <title property="foaf:name schema:name">Building Streaming and Cross-Environment Data Processing Pipelines with RDF-Connect</title>
  <link rel="stylesheet" media="screen" href="styles/screen.css" />
  <link rel="stylesheet" media="print"  href="styles/print.css" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  
  <meta name="citation_title" content="Building Streaming and Cross-Environment Data Processing Pipelines with RDF-Connect">
  <meta name="citation_author" content="Ieben Smessaert" />
  <meta name="citation_author" content="Arthur Vercruysse" />
  <meta name="citation_author" content="Julián Rojas Meléndez" />
  <meta name="citation_author" content="Pieter Colpaert" />
  
  <meta name="citation_publication_date" content="2025/05/19" />
</head>

<body prefix="dctypes: http://purl.org/dc/dcmitype/ pimspace: http://www.w3.org/ns/pim/space# rsa: http://www.w3.org/ns/auth/rsa# cert: http://www.w3.org/ns/auth/cert# wgs: http://www.w3.org/2003/01/geo/wgs84_pos# biblio: http://purl.org/net/biblio# bibo: http://purl.org/ontology/bibo/ book: http://purl.org/NET/book/vocab# ov: http://open.vocab.org/terms/ doap: http://usefulinc.com/ns/doap# dbr: http://dbpedia.org/resource/ dbp: http://dbpedia.org/property/ sio: http://semanticscience.org/resource/ opmw: http://www.opmw.org/ontology/ deo: http://purl.org/spar/deo/ doco: http://purl.org/spar/doco/ cito: http://purl.org/spar/cito/ fabio: http://purl.org/spar/fabio/ solid: http://www.w3.org/ns/solid/terms# acl: http://www.w3.org/ns/auth/acl# dio: https://w3id.org/dio# lsc: http://linkedscience.org/lsc/ns#" typeof="schema:CreativeWork sioc:Post prov:Entity lsc:Research">
  <header>
  <h1 id="building-streaming-and-cross-environment-data-processing-pipelines-with-rdf-connect">Building Streaming and Cross-Environment Data Processing Pipelines with RDF-Connect</h1>

  <ul id="authors">
    <li><a rev="lsc:participatesIn" property="foaf:maker schema:creator schema:author schema:publisher" href="https://smessaert.be" typeof="foaf:Person schema:Person" resource="https://solid.smessie.com/profile/card#me">Ieben Smessaert</a></li>
    <li><a rev="lsc:participatesIn" property="foaf:maker schema:creator schema:author schema:publisher" href="#" typeof="foaf:Person schema:Person" resource="https://data.knows.idlab.ugent.be/person/ajuvercr/#me">Arthur Vercruysse</a></li>
    <li><a rev="lsc:participatesIn" property="foaf:maker schema:creator schema:author schema:publisher" href="https://julianrojas.org/" typeof="foaf:Person schema:Person" resource="https://julianrojas.org/#me">Julián Rojas Meléndez</a></li>
    <li><a rev="lsc:participatesIn" property="foaf:maker schema:creator schema:author schema:publisher" href="https://pietercolpaert.be/" typeof="foaf:Person schema:Person" resource="https://pietercolpaert.be/#me">Pieter Colpaert</a></li>
  </ul>

  <ul id="affiliations">
    <li id="idlab">IDLab,
          Department of Electronics and Information Systems,
          Ghent University – imec</li>
  </ul>

  <center class="screen-only">
    <a href="https://github.com/rdf-connect/"><img src="img/rdf-connect.svg" height="300px" /></a>
</center>

  <section class="context">
    <p>Tutorial at <a href="https://iswc2025.semanticweb.org/#/calls/workshopstutorials" rel="as:inReplyTo">ISWC 2025</a>, November TBD 2025</p>
  </section>

  <p><br /></p>

  <section id="abstract" inlist="" rel="schema:hasPart" resource="#abstract">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Abstract</h2>
      <!-- Context -->
      <p><a href="https://github.com/rdf-connect/">RDF-Connect</a> is a novel, language-agnostic framework for building provenance-aware,
streaming data pipelines that integrate heterogeneous processors across programming languages. It aims on facilitating the construction, maintenance and reusability of modular and interoperable pipelines, supporting complex and semantically rich data workflows.
<!-- Need -->
Data processing pipelines are a crucial component of any data-centric system today,
including knowledge graph, LLM or in general, machine learning-based systems. 
Developers and researchers require flexible, interoperable tools for creating multilingual data processing pipelines.
<!-- Task -->
To meet this need, we present a comprehensive, tutorial that blends conceptual foundations with hands-on
experience. Through a series of guided tasks, participants will learn how to use RDF-Connect to design and execute
streaming pipelines that are reusable, extensible and transparent.
<br class="screen-only" />
<!-- Object -->
Participants will construct a streaming data processing pipeline based on a real-world data: generating a knowledge
graph from the Japan Meteorological Agency’s weather forecasts for Nara, Japan. They will: (i) Construct a machine
learning pipeline using processors in multiple programming languages, (ii) Create custom data processors for diverse
endpoints, (iii) Explore provenance tracking using RDF and PROV-O ontology.
<!-- Conclusion -->
By the end of the tutorial, participants from varied backgrounds—including Python, JavaScript, and Java developers—will
gain practical experience in building language-agnostic, semantically rich data processing pipelines.
<!-- Perspectives -->
This tutorial not only introduces RDF-Connect but also opens new avenues for interdisciplinary data transformation
strategies in Semantic Web research and development.</p>

    </div>
</section>

</header>

<section class="contents screen-only">
  <h2 id="contents">Contents</h2>
  <ul>
    <li><a href="#description">Description</a></li>
    <li><a href="#motivation">Motivation</a></li>
    <li><a href="#format">Format and Schedule</a></li>
    <li><a href="#material">Material</a></li>
    <li><a href="#audience">Audience</a></li>
    <li><a href="#presenters">Presenters</a></li>
    <li><a href="#requirements">Requirements</a></li>
  </ul>
</section>

<main>
  <!-- Add sections by specifying their file name, excluding the '.md' suffix. -->
  <section id="description" inlist="" rel="schema:hasPart" resource="#description">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Description</h2>

      <p id="description">This tutorial introduces <em>RDF-Connect (RDF-C)</em>, a novel, language-agnostic framework for constructing streaming data processing pipelines both for RDF and non-RDF data. By leveraging RDF and the PROV-O ontology, RDF-C enables the creation of pipelines that seamlessly integrate data processors implemented in multiple programming languages. The tutorial is centered around the core concepts of pipeline construction and processor development, giving participants the skills and understanding needed to build their own streaming workflows.</p>

      <p>Participants will gain hands-on experience with RDF-C, learning how to build pipelines by chaining together modular components – called processors – that each perform a specific operation on a (RDF) data stream. The tutorial focus on how to implement custom processors and integrate them into a functioning pipeline. Rather than emphasizing the solution to a specific data processing problem, the tutorial demonstrates how to structure and manage (RDF) data workflows that are adaptable across domains and use cases.</p>

      <p>To make the learning experience tangible, the tutorial includes a practical project based on a common use case for ISWC’s audience:
creating a <em>live</em> and multilingual RDF knowledge graph using data from the Meteorological Agency of Japan. This example illustrates how different processors can be combined – such as a REST API client in JavaScript, a Python-based ML model for language translation, a Java-based RML engine and SHACL validator, and a triple store (SPARQL) update processor.</p>

      <p>The expected outcome will be a functional pipeline created by the participants that integrates both existing and custom components within the RDF-Connect framework. The pipeline will continuosly extract and transform to RDF, weather forecast data from an API of the Japan Meteorological Agency. This data will be validated against a predefined schema using a SHACL validator. The data will be passed then to a custom processor, implemented by the participant, that performs language-aware transformations based on a machine learning model. Specifically, this processor will translate all literal objects tagged as Japanese (<code>@ja</code>) into English, generating new triples tagged as English (<code>@en</code>). The resulting RDF data will be written into a triple store using a SPARQL-based processor.</p>

      <p>By the end of the tutorial, participants will be able to:</p>

      <ul>
        <li>Design language-independent, modular data processing pipelines.</li>
        <li>Create custom processors for diverse data processing tasks within RDF-Connect.</li>
        <li>Leverage RDF and PROV-O to document and trace pipeline structure and execution.</li>
      </ul>

      <p>This tutorial is designed to empower researchers, developers, and data practitioners with the skills to build scalable, maintainable, and explainable streaming pipelines using RDF-based technologies.</p>

      <h2 id="motivation">Motivation</h2>

      <p id="motivation">As the Semantic Web community continues to embrace increasingly diverse data sources and application domains, there is a growing need for flexible, interoperable tooling that can bridge gaps between technologies, languages, and paradigms. <em>RDF-Connect (RDF-C)</em> directly addresses this need by providing a language-agnostic framework for building streaming data pipelines that are modular, reusable and traceable.</p>

      <p>Many Semantic Web workflows involve custom tooling built in specific languages, often leading to brittle, monolithic systems that are difficult to maintain, extend and reuse. RDF-C turns these challenges into opportunities by decoupling processing logic from implementation language and describing pipeline configurations using SHACL and an extension of the PROV-O ontology. This approach makes pipeline components easier to combine, reason about, and share across teams and communities.</p>

      <p>Moreover, the importance of provenance is growing rapidly, especially in the age of AI-generated content and automated
decision-making. RDF-C makes it easy to publish machine-readable documentation, in line with the FAIR principles, of the steps and transformations applied to data, facilitating transparency, reproducibility, and trust.</p>

      <p>This tutorial aims to fill a critical gap in current Semantic Web tooling by introducing a practical, extensible way to build
streaming data pipelines that are explainable and modular. It is particularly valuable for early-career researchers, practitioners building real-world applications, and anyone seeking to build more interoperable and maintainable data-centric systems.</p>

      <h2 id="format-and-schedule">Format and Schedule</h2>

      <p id="format">This tutorial is designed to be a <strong>full-day session</strong> as outlined in <a href="#planning">Table 1</a>, as it introduces a new framework
and guides participants through both conceptual foundations and hands-on implementation work.
A half-day format would not suffice to cover both the design principles of <em>RDFC</em> and provide meaningful experience
building pipelines and processors.</p>

      <p>The program is structured into four sessions, two in the morning and two in the afternoon, progressively building from a
conceptual overview to hands-on development.
The day concludes with a collaborative hackathon where participants apply what they’ve learned to explore extensions or
develop new applications.</p>

      <p>The <strong>first session</strong> introduces RDF-Connect at a high level, highlighting its language-agnostic processor architecture.
This session includes an overview of the tutorial’s content, as well as a detailed description of the pipeline
participants will build throughout the day.</p>

      <p>The <strong>second session</strong> focuses on processor development. Participants will learn how to implement a processor in a
language of their choice, and configure it for pipeline integration.
They will implement a processor that transforms a set of triples.
This processor will have to identify triples with a literal as the object and a language tag <code>@ja</code>.
It will then translate these triples to English and add them as a new triple with the language tag <code>@en</code>.
We can implement this using a lightweight ML model that translates input from Japanese to English locally.
Alternatively, we could implement a processor that sends the input to a remote translation service.</p>

      <p>The <strong>third session</strong> covers pipeline assembly using both existing and the custom-built processor from the previous
session.
Participants will construct a working streaming pipeline that pulls data, applies transformations, performs validation,
and publishes results to a triple store.</p>

      <p>The <strong>fourth session</strong> is a hackathon, where all participants work together to either extend the pipeline created in the
previous session with new data sources, or build a new pipeline using existing processors to achieve a different goal.</p>

      <figure id="planning" class="table">

        <table>
          <thead>
            <tr>
              <th> </th>
              <th>Topic</th>
              <th>Duration</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>Morning 1: Introduction</strong> (<em>1:20</em>)</td>
              <td>Introduction</td>
              <td>0:10</td>
            </tr>
            <tr>
              <td> </td>
              <td>Introduction to RDF-Connect Processors</td>
              <td>0:40</td>
            </tr>
            <tr>
              <td> </td>
              <td>Introduction to RDF-Connect Pipelines</td>
              <td>0:30</td>
            </tr>
            <tr>
              <td><em>Break</em></td>
              <td>—</td>
              <td>—</td>
            </tr>
            <tr>
              <td><strong>Morning 2: Processors</strong> (<em>1:20</em>)</td>
              <td>Recap: How to implement a RDFC Processor?</td>
              <td>0:10</td>
            </tr>
            <tr>
              <td> </td>
              <td>Hands-on: Implementing a processor</td>
              <td>1:10</td>
            </tr>
            <tr>
              <td><em>Lunch Break</em></td>
              <td>—</td>
              <td>—</td>
            </tr>
            <tr>
              <td><strong>Afternoon 1: Apps</strong> (<em>1:20</em>)</td>
              <td>Recap: How to build and execute a RDFC Pipeline?</td>
              <td>0:10</td>
            </tr>
            <tr>
              <td> </td>
              <td>Hands-on: Assembling a pipeline</td>
              <td>1:10</td>
            </tr>
            <tr>
              <td><em>Break</em></td>
              <td>—</td>
              <td>—</td>
            </tr>
            <tr>
              <td><strong>Afternoon 1: Hackathon</strong> (<em>1:20</em>)</td>
              <td>Hackathon</td>
              <td>1:20</td>
            </tr>
          </tbody>
        </table>

        <figcaption>
          <p><span class="label">Table 1:</span> Planning of the tutorial</p>
        </figcaption>
      </figure>

    </div>
</section>

  <section id="material" inlist="" rel="schema:hasPart" resource="#material">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Material</h2>

      <p>The tutorial is guided by slides, which are shared online.
For the hands-on coding sessions, we provide a git repository with separate branches for all sequentially completed tasks.
This will allow participants that are unable to complete a certain task,
to still begin with the next task by checking out a different branch.</p>

      <p>The slides and git repository are open for everyone under the CC BY 4.0 license.</p>

    </div>
</section>

  <section id="audience" inlist="" rel="schema:hasPart" resource="#audience">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Audience</h2>

      <p>This tutorial targets intermediate and advanced developers and researchers
who aim to understand, develop, or investigate data processing pipelines
using Semantic Web technologies. 
The tutorial is designed to accommodate
approximately 20 participants, who should possess a basic understanding
of Turtle, SHACL, and at least one of Python, JavaScript, or Java.</p>

    </div>
</section>

  <section id="presenters" inlist="" rel="schema:hasPart" resource="#presenters">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Presenters</h2>

      <p>This tutorial will be presented by Arthur Vercruysse{:.mandatory} (primary
contact: <a href="mailto:arthur.vercruysse@ugent.be">arthur.vercruysse@ugent.be</a>) and Ieben Smessaert from Ghent University –
imec.</p>

      <p>Arthur Vercruysse is a PhD student, who started his research journey with Knowledge Graph construction, and pivoted to
developer tooling with his love for compilers.</p>

      <p>Ieben Smessaert is a second year PhD student and one of the main developers and maintainers of the RDF-Connect
ecosystem.
He actively applies RDF-Connect in real-world use cases that include lifecycle management of DCAT-AP feeds within the
SEMIC community, and publication of geospatial knowledge graphs for the Flemish Institute for the sea.
Ieben also has experience by assisting practical sessions of
the <a href="http://rubenverborgh.github.io/WebFundamentals/">Web Development course</a>
by <a href="https://ruben.verborgh.org/">Ruben Verborgh</a> at Ghent University.</p>

    </div>
</section>

  <section id="requirements" inlist="" rel="schema:hasPart" resource="#requirements">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Requirements</h2>

      <p>For this tutorial, we require a projector to present our slides,
and a power plug for charging our laptop.</p>

      <p>The presenters and the participants need an internet connection.</p>

    </div>
</section>

</main>

<footer></footer>

</body>
</html>
