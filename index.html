<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta charset="utf-8" />
  <title property="foaf:name schema:name">Building Streaming and Cross-Environment Data Processing Pipelines with RDF-Connect</title>
  <link rel="stylesheet" media="screen" href="styles/screen.css" />
  <link rel="stylesheet" media="print"  href="styles/print.css" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  
  <meta name="citation_title" content="Building Streaming and Cross-Environment Data Processing Pipelines with RDF-Connect">
  <meta name="citation_author" content="Ieben Smessaert" />
  <meta name="citation_author" content="Arthur Vercruysse" />
  <meta name="citation_author" content="Julián Rojas Meléndez" />
  <meta name="citation_author" content="Pieter Colpaert" />
  
  <meta name="citation_publication_date" content="2025/05/06" />
</head>

<body prefix="dctypes: http://purl.org/dc/dcmitype/ pimspace: http://www.w3.org/ns/pim/space# rsa: http://www.w3.org/ns/auth/rsa# cert: http://www.w3.org/ns/auth/cert# wgs: http://www.w3.org/2003/01/geo/wgs84_pos# biblio: http://purl.org/net/biblio# bibo: http://purl.org/ontology/bibo/ book: http://purl.org/NET/book/vocab# ov: http://open.vocab.org/terms/ doap: http://usefulinc.com/ns/doap# dbr: http://dbpedia.org/resource/ dbp: http://dbpedia.org/property/ sio: http://semanticscience.org/resource/ opmw: http://www.opmw.org/ontology/ deo: http://purl.org/spar/deo/ doco: http://purl.org/spar/doco/ cito: http://purl.org/spar/cito/ fabio: http://purl.org/spar/fabio/ solid: http://www.w3.org/ns/solid/terms# acl: http://www.w3.org/ns/auth/acl# dio: https://w3id.org/dio# lsc: http://linkedscience.org/lsc/ns#" typeof="schema:CreativeWork sioc:Post prov:Entity lsc:Research">
  <header>
  <h1 id="building-streaming-and-cross-environment-data-processing-pipelines-with-rdf-connect">Building Streaming and Cross-Environment Data Processing Pipelines with RDF-Connect</h1>

  <ul id="authors">
    <li><a rev="lsc:participatesIn" property="foaf:maker schema:creator schema:author schema:publisher" href="https://smessaert.be" typeof="foaf:Person schema:Person" resource="https://solid.smessie.com/profile/card#me">Ieben Smessaert</a></li>
    <li><a rev="lsc:participatesIn" property="foaf:maker schema:creator schema:author schema:publisher" href="#" typeof="foaf:Person schema:Person" resource="https://data.knows.idlab.ugent.be/person/ajuvercr/#me">Arthur Vercruysse</a></li>
    <li><a rev="lsc:participatesIn" property="foaf:maker schema:creator schema:author schema:publisher" href="https://julianrojas.org/" typeof="foaf:Person schema:Person" resource="https://julianrojas.org/#me">Julián Rojas Meléndez</a></li>
    <li><a rev="lsc:participatesIn" property="foaf:maker schema:creator schema:author schema:publisher" href="https://pietercolpaert.be/" typeof="foaf:Person schema:Person" resource="https://pietercolpaert.be/#me">Pieter Colpaert</a></li>
  </ul>

  <ul id="affiliations">
    <li id="idlab">IDLab,
          Department of Electronics and Information Systems,
          Ghent University – imec</li>
  </ul>

  <center class="screen-only">
    <a href="https://github.com/rdf-connect/"><img src="img/rdf-connect.svg" height="300px" /></a>
</center>

  <section class="context">
    <p>Tutorial at <a href="https://iswc2025.semanticweb.org/#/calls/workshopstutorials" rel="as:inReplyTo">ISWC 2025</a>, November TBD 2025</p>
  </section>

  <p><br /></p>

  <section id="abstract" inlist="" rel="schema:hasPart" resource="#abstract">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Abstract</h2>
      <!-- Context -->
      <p><a href="https://github.com/rdf-connect/">RDF Connect</a> emerges as a groundbreaking solution to the fragmented landscape of data processing pipelines, offering a language-agnostic framework for building sophisticated, provenance-aware streaming data transformations.
<!-- Need -->
In an era of increasingly complex data ecosystems and the growing importance of Large Language Models (LLMs), developers and researchers require flexible, interoperable tools for creating multilingual data processing pipelines.
<!-- Task -->
To address this critical need, we present a comprehensive, hands-on tutorial designed to empower participants with the skills to leverage RDF Connect’s innovative capabilities.
<br class="screen-only" />
<!-- Object -->
The tutorial provides an immersive, full-day learning experience that combines theoretical insights with practical implementation. Participants will: (i) Construct a machine learning pipeline using processors in multiple programming languages, (ii) Create custom data processors for diverse endpoints, (iii) Explore provenance tracking using RDF and PROV-O ontology.
<!-- Conclusion -->
By the end of the tutorial, participants from varied backgrounds—including Python, JavaScript, and Java developers—will gain practical experience in building language-agnostic, semantically rich data processing pipelines.
<!-- Perspectives -->
This tutorial not only introduces RDF Connect but also opens new avenues for interdisciplinary data transformation strategies in semantic web research and development.</p>

    </div>
</section>

</header>

<main>
  <!-- Add sections by specifying their file name, excluding the '.md' suffix. -->
  <section id="description" inlist="" rel="schema:hasPart" resource="#description">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Description</h2>

      <p>This tutorial introduces RDF Connect (RDFC), a novel, language-agnostic framework for constructing streaming data processing pipelines. By leveraging the Resource Description Framework (RDF) and the PROV-O ontology, RDFC enables the creation of pipelines that seamlessly integrate processors implemented in multiple programming languages.</p>

      <p>Key Tutorial Highlights:</p>

      <ul>
        <li><strong>Language Agnostic</strong>: Create processors in any programming language</li>
        <li><strong>Provenance-Driven</strong>: Describe pipelines using RDF and PROV-O ontology</li>
        <li><strong>Hands-On Learning</strong>: Build custom processors and complete pipelines</li>
      </ul>

      <p>Tutorial Practical Project:
Participants will construct a machine learning pipeline that:</p>

      <ul>
        <li>Extracts weather data using JavaScript</li>
        <li>Ingests data into a Python-based ML model</li>
      </ul>

      <p>By the end of the tutorial, you’ll understand how to:</p>

      <ul>
        <li>Design language-independent data processing pipelines</li>
        <li>Create custom processors for diverse data sources</li>
        <li>Leverage RDF for comprehensive pipeline documentation</li>
      </ul>

      <h2 id="motivation">Motivation</h2>

      <p>In today’s fragmented data ecosystem, RDF libraries are spread across multiple programming languages, making data transformations complex and challenging. RDF Connect solves this by:</p>

      <ul>
        <li>Unifying data processing across language boundaries</li>
        <li>Enabling custom processors tailored to specific needs</li>
        <li>Providing comprehensive provenance tracking using PROV-O ontology</li>
      </ul>

      <p>With the rise of Large Language Models (LLMs), provenance has never been more critical. RDF Connect allows you to:
- Publish pipeline configurations alongside generated datasets
- Trace data lineage and origin
- Streamline machine learning training by intelligently pruning data sources</p>

      <h2 id="description">Format and Schedule</h2>

      <p>We plan a full day for this tutorial as shown in <a href="#planning">Table 1</a>.</p>

      <p>The tutorial is structured into four distinct sessions.</p>

      <p>The first session provides an introduction to RDF Connect, highlighting its language-agnostic processor architecture. This session includes an overview of the tutorial’s content, as well as a detailed description of the pipeline participants will build throughout the day.</p>

      <p>The second session delves into the process of building a custom processor. Participants will learn how to create a processor configuration and implement a client for the weather endpoint.</p>

      <p>The third session focuses on building a pipeline using the processor created in the previous session. Participants will build a machine learning pipeline that consumes the weather information in their favorite model.</p>

      <p>The fourth session is a hackathon, where all participants work together to either extend the pipeline created in the previous session with new data sources, or build a new pipeline using existing processors to achieve a different goal.</p>

      <figure id="planning" class="table">

        <table>
          <thead>
            <tr>
              <th> </th>
              <th>Topic</th>
              <th>Duration</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>Morning 1: Introduction</strong> (<em>1:20</em>)</td>
              <td>Introduction</td>
              <td>0:10</td>
            </tr>
            <tr>
              <td> </td>
              <td>Introduction to RDF Connect Processors</td>
              <td>0:40</td>
            </tr>
            <tr>
              <td> </td>
              <td>Introduction to RDF Connect Pipelines</td>
              <td>0:30</td>
            </tr>
            <tr>
              <td><em>Break</em></td>
              <td>—</td>
              <td>—</td>
            </tr>
            <tr>
              <td><strong>Morning 2: Processors</strong> (<em>1:20</em>)</td>
              <td>RDF Connect Processors</td>
              <td>0:40</td>
            </tr>
            <tr>
              <td> </td>
              <td>TBD</td>
              <td>0:40</td>
            </tr>
            <tr>
              <td><em>Lunch Break</em></td>
              <td>—</td>
              <td>—</td>
            </tr>
            <tr>
              <td><strong>Afternoon 1: Apps</strong> (<em>1:20</em>)</td>
              <td>RDF Connect Pipelines</td>
              <td>0:40</td>
            </tr>
            <tr>
              <td> </td>
              <td>TBD</td>
              <td>0:40</td>
            </tr>
            <tr>
              <td><em>Break</em></td>
              <td>—</td>
              <td>—</td>
            </tr>
            <tr>
              <td><strong>Afternoon 1: Hackathon</strong> (<em>1:20</em>)</td>
              <td>Hackathon</td>
              <td>1:20</td>
            </tr>
          </tbody>
        </table>

        <figcaption>
          <p><span class="label">Table 1:</span> Planning of the tutorial</p>
        </figcaption>
      </figure>

    </div>
</section>

  <section id="material" inlist="" rel="schema:hasPart" resource="#material">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Material</h2>

      <p>The tutorial is guided by slides, which are shared online.
For the hands-on coding sessions, we provide a git repository with separate branches for all sequentially completed tasks.
This will allow participants that are unable to complete a certain task,
to still begin with the next task by checking out a different branch.</p>

      <p>The slides and git repository are open for everyone under the CC BY 4.0 license.</p>

    </div>
</section>

  <section id="audience" inlist="" rel="schema:hasPart" resource="#audience">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Audience</h2>

      <p>This tutorial targets intermediate and advanced developers and researchers
who aim to understand, develop, or investigate data processing pipelines
using Semantic Web technologies. 
The tutorial is designed to accommodate
approximately 20 participants, who should possess a basic understanding
of Turtle, SHACL, and at least one of Python, JavaScript, or Java.</p>

    </div>
</section>

  <section id="presenters" inlist="" rel="schema:hasPart" resource="#presenters">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Presenters</h2>

      <p>This tutorial will be presented by Arthur Vercruysse{:.mandatory} (primary contact: <a href="mailto:arthur.vercruysse@ugent.be">arthur.vercruysse@ugent.be</a>) and Ieben Smessaert from Ghent University – imec.</p>

      <p>Arthur Vercruysse is a PhD student, who started his research journey with Knowledge Graph construction, and pivoted to developer tooling with his love for compilers.</p>

    </div>
</section>

  <section id="requirements" inlist="" rel="schema:hasPart" resource="#requirements">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Requirements</h2>

      <p>For this tutorial, we require a projector to present our slides,
and a power plug for charging our laptop.</p>

      <p>The presents and the partitioners need an internet connection.</p>

    </div>
</section>

</main>

<footer></footer>

</body>
</html>
